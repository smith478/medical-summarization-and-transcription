{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a4b8b5-bd21-4814-b1a8-6a2f7f927020",
   "metadata": {},
   "source": [
    "## Chexagent\n",
    "\n",
    "This is experimentation with the Chexagent model\n",
    "- [github](https://github.com/Stanford-AIMI/CheXagent)\n",
    "- [paper](https://arxiv.org/pdf/2401.12208.pdf)\n",
    "- [project](https://stanford-aimi.github.io/chexagent.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bde638-ac13-43e6-936a-9487405e70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83eefee-c41b-4993-b333-40fc727b1902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda\"\n",
    "# dtype = torch.float16\n",
    "\n",
    "device = \"cpu\"\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8bd8c5-c31d-4331-84d6-3d62533a66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"StanfordAIMI/CheXagent-8b\", trust_remote_code=True)\n",
    "generation_config = GenerationConfig.from_pretrained(\"StanfordAIMI/CheXagent-8b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"StanfordAIMI/CheXagent-8b\", torch_dtype=dtype, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59318fd9-ce2b-4bd5-94c1-d977c8ca4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Pleural_effusion-Metastatic_breast_carcinoma_Case_166_%285477628658%29.jpg\"\n",
    "# images = [Image.open(io.BytesIO(requests.get(image_path).content)).convert(\"RGB\")]\n",
    "image_path = \"../sample_images/Pleural_effusion-Metastatic_breast_carcinoma_Case_166_(5477628658).jpg\"\n",
    "images = [Image.open(image_path).convert(\"RGB\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3957039-5732-4d45-9e03-b989ca211c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90721f47-3875-45f9-bfe4-23a12373b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'Describe \"Airway\"'\n",
    "inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device=device, dtype=dtype)\n",
    "# inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device='cpu', dtype=dtype)\n",
    "output = model.generate(**inputs, generation_config=generation_config)[0]\n",
    "response = processor.tokenizer.decode(output, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd823a8-703b-4776-abb1-20c529178ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462e88d-cf5b-4de7-8916-d741487ccc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'Describe the main findings'\n",
    "inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device=device, dtype=dtype)\n",
    "# inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device='cpu', dtype=dtype)\n",
    "output = model.generate(**inputs, generation_config=generation_config)[0]\n",
    "response = processor.tokenizer.decode(output, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafd0c7e-36b8-438a-b56b-bacd9e6c94d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781043fe-b2b4-4e1b-bb96-5ed204427d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'Describe the abnormalities'\n",
    "inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device=device, dtype=dtype)\n",
    "# inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device='cpu', dtype=dtype)\n",
    "output = model.generate(**inputs, generation_config=generation_config)[0]\n",
    "response = processor.tokenizer.decode(output, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cead21-1b50-4bec-8f2d-1f0564e1a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b287213-7a7a-4556-8ec8-73554be23799",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'Write a radiology report for the following '\n",
    "inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device=device, dtype=dtype)\n",
    "# inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device='cpu', dtype=dtype)\n",
    "output = model.generate(**inputs, generation_config=generation_config)[0]\n",
    "response = processor.tokenizer.decode(output, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb48fa6-1b84-42cc-a8c6-959b3ba7aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9092631e-77c5-4734-a228-0f6b932b60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'What are your conclusions?'\n",
    "inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device=device, dtype=dtype)\n",
    "# inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device='cpu', dtype=dtype)\n",
    "output = model.generate(**inputs, generation_config=generation_config)[0]\n",
    "response = processor.tokenizer.decode(output, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e04394-ed44-41f2-bd14-b0ce57dee4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f28e638-d55a-482a-a9fe-955d00447b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'Can you classify the type of view of the radiograph?'\n",
    "inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device=device, dtype=dtype)\n",
    "# inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device='cpu', dtype=dtype)\n",
    "output = model.generate(**inputs, generation_config=generation_config)[0]\n",
    "response = processor.tokenizer.decode(output, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73444fd1-3cb6-4f15-8cb2-5b657c3f22b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec13232f-4890-42c3-8ff9-f5189a73d3b5",
   "metadata": {},
   "source": [
    "## Save the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062ceaf-209c-4b4a-80a8-a62069c13c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DIR = '../saved_models'\n",
    "MODEL = \"StanfordAIMI/CheXagent-8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a13449-e72a-469c-893b-4ebf4a762849",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"{LOCAL_DIR}/{MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cccdb8-0df4-40bf-be7e-9a96117ace36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
