{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917032e2-1d2b-461b-92fb-2808cdeba85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e86772-8786-411c-ba38-abf4e16e4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3bda51-207d-4922-ac63-5ec1b6578f9a",
   "metadata": {},
   "source": [
    "## Load the pubmed summarization dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f8b39-60f4-4603-8c21-85b8ee1c315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ccdv/pubmed-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65e864-5daa-4d74-b90a-b9c1c55151ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Features: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9ec6f-abd4-4221-aa18-7ecf2d581791",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset['train'][1]\n",
    "print(f\"\"\"\n",
    "Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n",
    "\"\"\")\n",
    "print(sample['article'][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"abstract\"])}):')\n",
    "print(sample[\"abstract\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae422f36-c0f9-4a65-8b9f-bc4056bbd18b",
   "metadata": {},
   "source": [
    "## Load the pretrained models\n",
    "\n",
    "We could also load these models using `AutoModel` and `AutoTokenizer` to find the maximum input length. It would look something like:\n",
    "\n",
    "```python\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = 'Falconsai/medical_summarization'\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Get the maximum input size\n",
    "max_input_size = model.config.max_position_embeddings\n",
    "print(f\"The maximum input size of the model is: {max_input_size}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c863c-5cde-4634-80fa-fd2604b90b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_falconsai = pipeline(\"summarization\", model=\"Falconsai/medical_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68830ba-6b53-4711-bc27-6a6f12864f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_longt5 = pipeline(\"summarization\", model=\"Stancld/longt5-tglobal-large-16384-pubmed-3k_steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812f694-273f-4a71-be5e-e1c1b57c4522",
   "metadata": {},
   "source": [
    "## Sample text comparison\n",
    "\n",
    "Here we'll take the first 3000 characters in order to have the same input for each of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b7d49-93f3-4f1a-af5b-87334097d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = sample['article'][:3000]\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e7564-239b-441c-b3e4-720d90cf12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b41c01-e05e-4fad-9ba0-4b8bce79e852",
   "metadata": {},
   "source": [
    "## Evaluate pretrained models\n",
    "\n",
    "As a baseline we will use the first three sentences as the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673de4a-489e-4d86-8255-388596ace7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43776f97-8fba-4e86-8cb2-ba27fbee7357",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f784993-2b79-4bc0-ba1d-7820ebb611ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685e7cc-51b6-4d0c-8c13-131353e758c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[\"baseline\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb06bf-5b4c-4788-8628-0ba971ab5274",
   "metadata": {},
   "source": [
    "#### Falconsai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878424d5-3fab-44eb-9595-023eecf77078",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = summarizer_falconsai(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4789fe-ab35-44ad-903c-904d27c2e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a1bb1-0f16-485a-b7d8-ffbdc57c2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[\"falconsai\"] = \"\\n\".join(sent_tokenize(output[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f19a9-208a-439c-b337-c46199121d92",
   "metadata": {},
   "source": [
    "#### long t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367ab04-c219-49f7-ba96-e37ef3a4167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = summarizer_longt5(sample_text, max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dba02c-883b-4bf2-a80e-8a157eca58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a146969d-06b0-47be-981d-0aaf8e38fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[\"longt5\"] = \"\\n\".join(sent_tokenize(output[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec21a7f2-236b-4936-8824-96021725b4e2",
   "metadata": {},
   "source": [
    "## Comparing different summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64535522-689a-45cc-88e9-1c064a1e0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GROUND TRUTH\")\n",
    "print(sample['abstract'])\n",
    "print(\"\")\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68633112-5c7a-4cbd-a985-c981826155b5",
   "metadata": {},
   "source": [
    "## Evaluate quality of summaries\n",
    "\n",
    "We will use the ROUGE metric to compare the quality of different summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e1113-3d45-4fbe-91d6-21d6218c8826",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde492ea-f17d-4740-bde2-660f757f46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = sample['abstract']\n",
    "records = []\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "for model_name in summaries:\n",
    "    rouge_metric.add(prediction=summaries[model_name], reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "    records.append(rouge_dict)\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d6133-39ad-4f90-b919-dd8c5d264c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
